# ğŸ¤ Real-Time Emotion Detection - Complete System

A complete real-time emotion detection system that captures audio from your microphone and displays emotions with beautiful visualizations.

## âœ¨ Features

âœ… **Real-Time Microphone Capture** - Automatic audio input from your microphone  
âœ… **Live Emotion Detection** - Detects emotions every 2 seconds  
âœ… **Beautiful Displays** - 3 visualization options (Terminal, Web, or Simple)  
âœ… **Confidence Scores** - Shows how confident the model is  
âœ… **Probability Breakdown** - All emotion scores visualized  
âœ… **AI Responses** - Context-aware responses based on detected emotion  
âœ… **No File Recording** - Everything happens in memory  
âœ… **7 Emotion Types** - Angry, Happy, Sad, Neutral, Fear, Disgust, Surprise  

## ğŸš€ Quick Start (30 seconds)

### Terminal 1 - Start Backend API
```bash
cd emotion-backend
uvicorn app.server:app --host 0.0.0.0 --port 8000
```

### Terminal 2 - Start Emotion Display
```bash
cd emotion-backend
python terminal_display.py
```

**Then speak into your microphone!** ğŸ™ï¸

## ğŸ¨ Display Options

### Option 1: Terminal Display â­ (RECOMMENDED)
Beautiful real-time emotion visualization directly in your terminal.

```bash
python terminal_display.py
```

**Shows:**
- Large emoji of detected emotion
- Confidence percentage with visual bar
- AI response message
- Probability breakdown for all emotions
- Real-time updates

### Option 2: Web Dashboard ğŸŒ
Modern web interface with animations and gradient styling.

```bash
python dashboard.py
```

**Then open:** http://localhost:8001

**Features:**
- Beautiful UI with gradients
- WebSocket real-time updates
- Smooth animations
- Professional dashboard look

### Option 3: Simple Script âš™ï¸
Lightweight Python-only version.

```bash
python realtime_emotion_sd.py
```

**Or use the Interactive Launcher:**
```bash
python launcher.py
```

## ğŸ“Š System Architecture

```
Microphone â†’ SoundDevice/PyAudio â†’ Audio Buffer â†’ FastAPI Backend
                                        â†“
                                  Emotion Detection Model
                                        â†“
                              Display (Terminal/Web/Console)
```

## ğŸ¯ Supported Emotions

| Code | Emotion | Emoji | Example Response |
|------|---------|-------|------------------|
| ang | Angry | ğŸ˜  | "I sense frustration. Let me help resolve this quickly." |
| hap | Happy | ğŸ˜Š | "You sound upbeat! Great to hear. How can I assist further?" |
| sad | Sad | ğŸ˜¢ | "I'm here for you. Would you like me to simplify this step?" |
| neu | Neutral | ğŸ˜ | "Got it. I'll proceed." |
| fear | Fear | ğŸ˜¨ | "No worries, I'll guide you through it." |
| dis | Disgust | ğŸ¤¢ | "Understood. Let me find a better alternative." |
| sur | Surprise | ğŸ˜² | "That was unexpected! Do you want more details?" |

## ğŸ“ Files Explained

| File | Purpose |
|------|---------|
| `terminal_display.py` | Main terminal display with beautiful formatting |
| `dashboard.py` | Web dashboard with WebSocket support |
| `realtime_emotion_sd.py` | Simple script using SoundDevice |
| `realtime_emotion.py` | Alternative using PyAudio |
| `launcher.py` | Interactive menu launcher |
| `quickstart.py` | Setup verification tool |
| `DISPLAY_GUIDE.md` | Complete display setup documentation |

## âš™ï¸ Configuration

Edit these values in the display scripts to customize behavior:

```python
API_URL = "http://localhost:8000/predict"  # Backend endpoint
SAMPLE_RATE = 16000                         # Audio sample rate (Hz)
CHANNELS = 1                                # Mono audio
BUFFER_DURATION = 2                         # Process every 2 seconds
CHUNK_DURATION = 0.5                        # Audio chunk size
```

## ğŸ”§ Requirements

```
fastapi==0.115.0
uvicorn[standard]==0.30.6
transformers==4.44.2
torch
torchaudio
sounddevice
soundfile==0.12.1
librosa==0.10.2.post1
requests
numpy
pydantic==2.8.2
```

Install with:
```bash
pip install -r requirements.txt
```

## ğŸ› Troubleshooting

### Backend API not running
```bash
# Check if port 8000 is in use
netstat -an | find ":8000"

# Start backend without reload mode if having issues
uvicorn app.server:app --host 0.0.0.0 --port 8000 --workers 1
```

### Microphone not detected
- Check available devices: List shown in script output
- Try different input devices (index shown in list)
- Verify microphone is not muted in Windows settings

### API connection errors
- Verify backend is running: `curl http://localhost:8000/health`
- Check firewall settings
- Try restarting both backend and display

### No emotions detected
- Speak louder into the microphone
- Check audio levels in Windows settings
- Ensure microphone has proper permissions
- Try different microphone device

## ğŸ“Š Real Output Example

```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  ğŸ¤ REAL-TIME EMOTION DETECTION DASHBOARD
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    ğŸ˜Š  HAPPY  ğŸ˜Š                              â•‘
â•‘                                                                â•‘
â•‘  Confidence: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘] 87%            â•‘
â•‘                                                                â•‘
â•‘  ğŸ’¬ You sound upbeat! Great to hear. How can I assist?        â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Emotion Probabilities:                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  HAP      [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘] 87%                        â”‚
â”‚  NEU      [â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 8%                        â”‚
â”‚  SAD      [â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 3%                       â”‚
â”‚  ANG      [â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 1%                       â”‚
â”‚  FEAR     [â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 1%                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

âœ… Status: Connected | Time: 14:25:33
```

## ğŸŒ API Endpoints

### Health Check
```
GET http://localhost:8000/health

Response:
{
  "status": "ok",
  "model": "superb/wav2vec2-base-superb-er",
  "device": "cpu"
}
```

### Predict Emotion
```
POST http://localhost:8000/predict

Body: multipart/form-data with audio file

Response:
{
  "label": "hap",
  "score": 0.8745,
  "probs": {
    "hap": 0.8745,
    "neu": 0.0832,
    "sad": 0.0281,
    "ang": 0.0142
  },
  "response": "You sound upbeat! Great to hear..."
}
```

## ğŸ“ How It Works

1. **Audio Capture** - Microphone audio is captured in real-time
2. **Buffering** - Audio is accumulated for 2 seconds
3. **Preprocessing** - Audio is converted to 16kHz mono PCM
4. **Detection** - Wav2Vec2-based emotion classification model
5. **Response** - Context-aware AI response based on emotion
6. **Display** - Results shown in terminal or web dashboard

## ğŸ” Privacy & Security

- All audio processing is local (no cloud upload)
- Audio data is processed in memory only
- No files are saved to disk
- No personal data collection
- Works completely offline (after model download)

## ğŸ“ˆ Performance

- **Latency**: ~2 seconds (detection interval)
- **CPU Usage**: ~20-30% on Intel i5 (varies by device)
- **Memory**: ~1-2 GB (model + buffers)
- **Disk**: Model downloaded once (~400MB)

## ğŸ¯ Use Cases

- **Customer Service** - Detect customer frustration
- **Education** - Monitor student engagement
- **Mental Health** - Track emotional patterns
- **Gaming** - Adapt game difficulty to player emotion
- **Research** - Emotion recognition studies
- **Testing** - QA testing with emotional feedback

## ğŸ“ Support

For issues or questions:
1. Check the DISPLAY_GUIDE.md for detailed help
2. Verify backend is running: `curl http://localhost:8000/health`
3. Check REALTIME_README.md for microphone setup
4. Review error messages in console output

## ğŸ“„ License

MIT License - Feel free to use and modify

## ğŸ™ Acknowledgments

- **Model**: Wav2Vec2 from Hugging Face (fine-tuned on emotion data)
- **Framework**: FastAPI for backend API
- **Audio**: SoundDevice/PyAudio for microphone input
- **Display**: ASCII art and Unicode for beautiful terminal output

---

**Happy emotion detecting!** ğŸ‰

For more details, see REALTIME_README.md and DISPLAY_GUIDE.md

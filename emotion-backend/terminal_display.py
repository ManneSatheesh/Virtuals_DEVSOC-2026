#!/usr/bin/env python
"""
Terminal-based real-time emotion display
Captures microphone and shows beautiful emotion visualization in terminal
"""
import sounddevice as sd
import numpy as np
import requests
import time
from datetime import datetime
from collections import deque

# Configuration
API_URL = "http://localhost:8000/predict"
SAMPLE_RATE = 16000
CHANNELS = 1
BUFFER_DURATION = 2
BUFFER_SIZE = int(SAMPLE_RATE * BUFFER_DURATION)
CHUNK_DURATION = 0.5

class TerminalEmotionDisplay:
    def __init__(self):
        self.audio_buffer = deque(maxlen=BUFFER_SIZE)
        self.is_recording = False
        self.history = deque(maxlen=5)  # Keep last 5 emotions
        
    def clear_screen(self):
        """Clear terminal screen"""
        import os
        os.system('cls' if os.name == 'nt' else 'clear')
    
    def print_header(self):
        """Print dashboard header"""
        print("\n" + "‚ñà" * 70)
        print("‚ïë" + " " * 68 + "‚ïë")
        print("‚ïë" + "  üé§ REAL-TIME EMOTION DETECTION DASHBOARD".center(68) + "‚ïë")
        print("‚ïë" + " " * 68 + "‚ïë")
        print("‚ñà" * 70)
    
    def print_emotion_box(self, emotion_data):
        """Print emotion display box"""
        if not emotion_data:
            print("\n" + "‚ïî" + "‚ïê" * 68 + "‚ïó")
            print("‚ïë" + "  Waiting for audio input...".center(68) + "‚ïë")
            print("‚ïö" + "‚ïê" * 68 + "‚ïù\n")
            return
        
        label = emotion_data['label']
        score = emotion_data['score']
        response = emotion_data['response']
        probs = emotion_data['probs']
        
        emoji_map = {
            'ang': 'üò†',
            'hap': 'üòä',
            'sad': 'üò¢',
            'neu': 'üòê',
            'fear': 'üò®',
            'dis': 'ü§¢',
            'sur': 'üò≤'
        }
        
        name_map = {
            'ang': 'ANGRY',
            'hap': 'HAPPY',
            'sad': 'SAD',
            'neu': 'NEUTRAL',
            'fear': 'FEAR',
            'dis': 'DISGUST',
            'sur': 'SURPRISE'
        }
        
        emoji = emoji_map.get(label, 'üé§')
        name = name_map.get(label, label.upper())
        confidence = int(score * 100)
        
        # Main emotion box
        print("\n" + "‚ïî" + "‚ïê" * 68 + "‚ïó")
        print("‚ïë" + f"  {emoji}  {name}  {emoji}".center(68) + "‚ïë")
        print("‚ïë" + " " * 68 + "‚ïë")
        
        # Confidence bar
        bar_length = 50
        filled = int(bar_length * score)
        bar = "‚ñà" * filled + "‚ñë" * (bar_length - filled)
        print("‚ïë" + f"  Confidence: [{bar}] {confidence}%".ljust(68) + "‚ïë")
        print("‚ïë" + " " * 68 + "‚ïë")
        
        # Response
        response_line = response[:65]
        print("‚ïë" + f"  üí¨ {response_line}".ljust(68) + "‚ïë")
        print("‚ïö" + "‚ïê" * 68 + "‚ïù")
        
        # Probability breakdown
        print("\n" + "‚îå" + "‚îÄ" * 68 + "‚îê")
        print("‚îÇ" + "  Emotion Probabilities:".ljust(68) + "‚îÇ")
        print("‚îú" + "‚îÄ" * 68 + "‚î§")
        
        sorted_probs = sorted(probs.items(), key=lambda x: x[1], reverse=True)
        for emotion, prob in sorted_probs:
            percentage = int(prob * 100)
            bar_filled = int(20 * prob)
            bar = "‚ñà" * bar_filled + "‚ñë" * (20 - bar_filled)
            emotion_name = name_map.get(emotion, emotion.upper()).ljust(8)
            print("‚îÇ  " + f"{emotion_name} [{bar}] {percentage:>3}%".ljust(66) + "‚îÇ")
        
        print("‚îî" + "‚îÄ" * 68 + "‚îò")
    
    def print_status(self, connected=True, buffer_size=0):
        """Print connection and buffer status"""
        status_icon = "üü¢" if connected else "üî¥"
        connection_text = "Connected" if connected else "Disconnected"
        
        print("\n" + "‚ïî" + "‚ïê" * 68 + "‚ïó")
        print("‚ïë" + f"  Status: {status_icon} {connection_text} | Buffer: {buffer_size}/{BUFFER_SIZE}".ljust(68) + "‚ïë")
        print("‚ïë" + f"  Time: {datetime.now().strftime('%H:%M:%S')}".ljust(68) + "‚ïë")
        print("‚ïë" + "  Press Ctrl+C to stop".ljust(68) + "‚ïë")
        print("‚ïö" + "‚ïê" * 68 + "‚ïù\n")
    
    def audio_callback(self, indata, frames, time_info, status):
        """Audio callback to capture microphone data"""
        if status:
            print(f"‚ö†Ô∏è  Audio status: {status}")
        
        audio_data = indata[:, 0].astype(np.float32)
        self.audio_buffer.extend(audio_data)
    
    def send_audio_chunk(self, audio_chunk):
        """Send audio to backend and get emotion"""
        try:
            import io
            import soundfile as sf
            
            buffer = io.BytesIO()
            sf.write(buffer, audio_chunk, SAMPLE_RATE, format='WAV')
            buffer.seek(0)
            
            files = {'file': ('audio.wav', buffer, 'audio/wav')}
            response = requests.post(API_URL, files=files, timeout=10)
            
            if response.status_code == 200:
                return response.json()
            else:
                print(f"‚ùå API Error: {response.status_code}")
                return None
                
        except Exception as e:
            print(f"‚ùå Error: {e}")
            return None
    
    def run(self):
        """Start the terminal display"""
        self.is_recording = True
        
        try:
            self.print_header()
            print("\nüéôÔ∏è  Initializing microphone...\n")
            
            # List devices
            print("Available audio devices:")
            devices = sd.query_devices()
            for i, device in enumerate(devices):
                if device['max_input_channels'] > 0:
                    default = "[DEFAULT]" if i == sd.default.device[0] else ""
                    print(f"  [{i}] {device['name']} {default}")
            print()
            
            with sd.InputStream(
                channels=CHANNELS,
                samplerate=SAMPLE_RATE,
                callback=self.audio_callback,
                blocksize=int(SAMPLE_RATE * CHUNK_DURATION)
            ):
                print("‚úÖ Microphone active!\n")
                self.print_status(connected=True)
                
                current_emotion = None
                last_update = time.time()
                
                while self.is_recording:
                    # Process audio every 2 seconds
                    if len(self.audio_buffer) >= BUFFER_SIZE:
                        audio_chunk = np.array(list(self.audio_buffer), dtype=np.float32)
                        
                        # Clear screen and display
                        self.clear_screen()
                        self.print_header()
                        
                        # Send to backend
                        print("\n‚è≥ Processing audio...\n")
                        emotion_data = self.send_audio_chunk(audio_chunk)
                        
                        if emotion_data:
                            current_emotion = emotion_data
                            self.history.append(emotion_data)
                        
                        last_update = time.time()
                    
                    # Display current emotion
                    self.clear_screen()
                    self.print_header()
                    self.print_emotion_box(current_emotion)
                    self.print_status(connected=True, buffer_size=len(self.audio_buffer))
                    
                    time.sleep(0.5)
        
        except KeyboardInterrupt:
            print("\n\n" + "‚ñà" * 70)
            print("‚ïë" + "  üëã Thanks for using Emotion Detection!".center(68) + "‚ïë")
            print("‚ñà" * 70 + "\n")
        
        except Exception as e:
            print(f"\n‚ùå Error: {e}")
            print(f"Make sure the backend API is running on port 8000")
        
        finally:
            self.is_recording = False

if __name__ == "__main__":
    display = TerminalEmotionDisplay()
    display.run()
